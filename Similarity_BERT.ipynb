{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Similarity_BERT.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pam-lab/JupyterFiles/blob/main/Similarity_BERT.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DGN9O0G3uxvE",
        "outputId": "ab50831f-c788-4855-80d1-354f05ecde34"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Wed Jun  8 15:03:45 2022       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   39C    P0    38W / 250W |   1521MiB / 16280MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Loading and processing"
      ],
      "metadata": {
        "id": "O67Vn__gWwG8"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZiTZi38tNA-R",
        "outputId": "59f9dc03-cacc-4891-d9a6-34863bf3a0a1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'course-nlp-ir-1-text-exploring' already exists and is not an empty directory.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/language-ml/course-nlp-ir-1-text-exploring"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import random \n",
        "import nltk\n",
        "import pandas as pd\n",
        "import codecs\n",
        "import tqdm\n",
        "\n",
        "quranic_dir = \"/content/course-nlp-ir-1-text-exploring/exploring-datasets/religious_text\"\n",
        "df_quran = pd.read_csv(f'{quranic_dir}/quranic_data/id_text_with_orthographies.txt', sep='\\t', header=None)\n",
        "df_nahj = pd.read_csv(f'{quranic_dir}/nahj-al-balaqa/Nahj Al-Balaqa.txt', sep='\\t',header=None)\n",
        "verse_complete_dict = pd.Series(df_quran[1].tolist(), index=df_quran[0]).to_dict()\n",
        "nahj_complete_dict = pd.Series(df_nahj[1].tolist(), index=df_nahj[0]).to_dict()"
      ],
      "metadata": {
        "id": "qqOLyjhGS3cx"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pathlib import Path\n",
        "import re\n",
        "sahife_text=Path(f'{quranic_dir}/Saheefa/sahife_sajjadieh.txt').read_text().split('\\n')\n",
        "sahife_complete_dict = [re.sub('[(][۰-۹]+[)]','', item) for item in sahife_text if item.startswith('(')]"
      ],
      "metadata": {
        "id": "XQ5yonDq5RmL"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sahife_complete_dict[12]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "zYmWmMuZ6NKq",
        "outputId": "80a81f43-cd37-43d1-bcd6-dcedae50d73d"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "' حَمْداً یَرْتَفِعُ مِنَّا إِلَی أَعْلَی عِلِّیِّینَ فِي کِتَابٍ مَرْقُومٍ یَشْهَدُه\\u200cُ الْمُقَرَّبُونَ. '"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nahj_complete_dict['2##186']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "cCiaD8k30_CF",
        "outputId": "66603e20-1332-48e4-aeec-46f23946f846"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'وَ قَالَ ع لِلظّالِمِ الباَدیِ غَداً بِکَفّهِ عَضّةٌ'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "verse_complete_dict['2##186']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "hG44UkxzTSj_",
        "outputId": "d30b39cc-d720-469f-9ded-b5bf9c28183b"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'وَإِذَا سَأَلَكَ عِبَادِي عَنِّي فَإِنِّي قَرِيبٌ ۖ أُجِيبُ دَعْوَةَ الدَّاعِ إِذَا دَعَانِ ۖ فَلْيَسْتَجِيبُوا لِي وَلْيُؤْمِنُوا بِي لَعَلَّهُمْ يَرْشُدُونَ'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Normalize"
      ],
      "metadata": {
        "id": "x0Qok8hCW-MM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install -Uq camel_tools"
      ],
      "metadata": {
        "id": "dWoFs-Z7VNhh"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from camel_tools.utils.normalize import normalize_unicode\n",
        "from camel_tools.utils.normalize import normalize_alef_maksura_ar\n",
        "from camel_tools.utils.normalize import normalize_alef_ar\n",
        "\n",
        "from camel_tools.utils.normalize import normalize_alef_bw\n",
        "from camel_tools.utils.normalize import normalize_alef_hsb\n",
        "\n",
        "from camel_tools.utils.normalize import normalize_teh_marbuta_ar\n",
        "from camel_tools.utils.dediac import dediac_ar\n",
        "\n",
        "def normalize_arabic(sentence):\n",
        "\n",
        "    # Normalize alef variants to 'ا'\n",
        "    sent_norm = normalize_unicode(sentence)\n",
        "    \n",
        "    sent_norm = normalize_alef_bw(sent_norm)\n",
        "    # Normalize alef variants to 'ا'\n",
        "    sent_norm = normalize_alef_ar(sentence)\n",
        "\n",
        "    # Normalize alef maksura 'ى' to yeh 'ي'\n",
        "    sent_norm = normalize_alef_maksura_ar(sent_norm)\n",
        "\n",
        "    # Normalize teh marbuta 'ة' to heh 'ه'\n",
        "    sent_norm = normalize_teh_marbuta_ar(sent_norm)\n",
        "    return dediac_ar(sent_norm)"
      ],
      "metadata": {
        "id": "SBZgSk_qVfPf"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from camel_tools.utils import normalize\n",
        "\n",
        "\n",
        "verse_complete_dict_nrmlz = {k:normalize_arabic(v) for k,v in tqdm.tqdm(verse_complete_dict.items())}\n",
        "nahj_complete_dict_nrmlz = {k:normalize_arabic(v) for k,v in tqdm.tqdm(nahj_complete_dict.items())}\n",
        "sahife_complete_dict_nrmlz = [normalize_arabic(item) for item in tqdm.tqdm(sahife_complete_dict)]"
      ],
      "metadata": {
        "id": "PgTbrIJQV6Do",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c1671c8a-4d9d-4ffe-9374-88d843130d9a"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 6236/6236 [00:00<00:00, 17809.04it/s]\n",
            "100%|██████████| 800/800 [00:00<00:00, 4062.80it/s]\n",
            "100%|██████████| 924/924 [00:00<00:00, 9317.49it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(verse_complete_dict['2##186'])\n",
        "print(verse_complete_dict_nrmlz['2##186'])\n",
        "\n",
        "print(nahj_complete_dict['2##186'])\n",
        "print(nahj_complete_dict_nrmlz['2##186'])\n",
        "\n",
        "print(sahife_complete_dict[34])\n",
        "print(sahife_complete_dict_nrmlz[34])"
      ],
      "metadata": {
        "id": "VhfSxrvmWDYr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eb06e21a-b45c-4675-b684-33d5dc5737b0"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "وَإِذَا سَأَلَكَ عِبَادِي عَنِّي فَإِنِّي قَرِيبٌ ۖ أُجِيبُ دَعْوَةَ الدَّاعِ إِذَا دَعَانِ ۖ فَلْيَسْتَجِيبُوا لِي وَلْيُؤْمِنُوا بِي لَعَلَّهُمْ يَرْشُدُونَ\n",
            "واذا سالك عبادي عني فاني قريب ۖ اجيب دعوه الداع اذا دعان ۖ فليستجيبوا لي وليؤمنوا بي لعلهم يرشدون\n",
            "وَ قَالَ ع لِلظّالِمِ الباَدیِ غَداً بِکَفّهِ عَضّةٌ\n",
            "و قال ع للظالم البادی غدا بکفه عضه\n",
            " وَ کَاشَفَ فِي الدُّعَاءِ إِلَیْکَ حَامَّتَه‌ُ \n",
            " و کاشف في الدعاء الیک حامته‌ \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "quranic_tokenized = [sents.split() for sents in tqdm.tqdm(verse_complete_dict_nrmlz.values())]\n",
        "nahj_tokenized = [sents.split() for sents in tqdm.tqdm(nahj_complete_dict_nrmlz.values())]\n",
        "sahife_tokenized = [sents.split() for sents in tqdm.tqdm(sahife_complete_dict_nrmlz)]"
      ],
      "metadata": {
        "id": "MPLCLAWyWvJ7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8524372f-f549-4e95-f657-e00dd8cbf423"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 6236/6236 [00:00<00:00, 161319.38it/s]\n",
            "100%|██████████| 800/800 [00:00<00:00, 77200.52it/s]\n",
            "100%|██████████| 924/924 [00:00<00:00, 238773.76it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "size_quran_token = [len(sentence) for sentence in quranic_tokenized]\n",
        "size_nahj_token =[len(sentence) for sentence in nahj_tokenized]\n",
        "size_sahife_token = [len(sentence) for sentence in sahife_tokenized]\n",
        "fig,axes=plt.subplots(nrows=1,ncols=3,figsize=(10,5))\n",
        "axes[0].hist(size_quran_token)\n",
        "axes[1].hist(size_nahj_token)\n",
        "axes[2].hist(size_sahife_token)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "PDgW8svJlBc0",
        "outputId": "6e395211-3153-48cb-d059-bebb04524dd5"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([224., 255., 200., 122.,  69.,  32.,  16.,   3.,   2.,   1.]),\n",
              " array([  3. ,  13.7,  24.4,  35.1,  45.8,  56.5,  67.2,  77.9,  88.6,\n",
              "         99.3, 110. ]),\n",
              " <a list of 10 Patch objects>)"
            ]
          },
          "metadata": {},
          "execution_count": 19
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 720x360 with 3 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Common Modules"
      ],
      "metadata": {
        "id": "8AztaLi1pTil"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install transformers -Uqq"
      ],
      "metadata": {
        "id": "tbfP7hP4pSb-"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def tokenize(sentence_list):\n",
        "    return tokenizer.batch_encode_plus(sentence_list,\n",
        "                    add_special_tokens=True,\n",
        "                    max_length=128,\n",
        "                    padding='max_length',\n",
        "                    return_attention_mask=True,\n",
        "                    truncation=True,\n",
        "                    return_tensors='pt')"
      ],
      "metadata": {
        "id": "MMmEqb0dlxHN"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "CaSfL1uPpi2K"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Similarity without finetuning"
      ],
      "metadata": {
        "id": "OOZS_IvAHklC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Loading Bert Model"
      ],
      "metadata": {
        "id": "4AcRU18kHRMB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer, AutoModel\n",
        "import torch\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "\n",
        "# Mini:   asafaya/bert-mini-arabic\n",
        "# Medium: asafaya/bert-medium-arabic\n",
        "# Base:   asafaya/bert-base-arabic\n",
        "# Large:  asafaya/bert-large-arabic\n",
        "# https://www.youtube.com/watch?v=jVPd7lEvjtg\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"asafaya/bert-base-arabic\")\n",
        "model = AutoModel.from_pretrained(\"asafaya/bert-base-arabic\")\n",
        "\n",
        "model=model.to(device)\n",
        "\n",
        "model.eval()"
      ],
      "metadata": {
        "id": "sm5hDzwI8IKi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b2f9bebb-eee6-488f-d904-3dd7c703b4d3"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at asafaya/bert-base-arabic were not used when initializing BertModel: ['cls.predictions.decoder.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BertModel(\n",
              "  (embeddings): BertEmbeddings(\n",
              "    (word_embeddings): Embedding(32000, 768, padding_idx=0)\n",
              "    (position_embeddings): Embedding(512, 768)\n",
              "    (token_type_embeddings): Embedding(2, 768)\n",
              "    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "    (dropout): Dropout(p=0.1, inplace=False)\n",
              "  )\n",
              "  (encoder): BertEncoder(\n",
              "    (layer): ModuleList(\n",
              "      (0): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (intermediate_act_fn): GELUActivation()\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (1): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (intermediate_act_fn): GELUActivation()\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (2): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (intermediate_act_fn): GELUActivation()\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (3): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (intermediate_act_fn): GELUActivation()\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (4): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (intermediate_act_fn): GELUActivation()\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (5): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (intermediate_act_fn): GELUActivation()\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (6): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (intermediate_act_fn): GELUActivation()\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (7): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (intermediate_act_fn): GELUActivation()\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (8): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (intermediate_act_fn): GELUActivation()\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (9): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (intermediate_act_fn): GELUActivation()\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (10): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (intermediate_act_fn): GELUActivation()\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (11): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (intermediate_act_fn): GELUActivation()\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (pooler): BertPooler(\n",
              "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "    (activation): Tanh()\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Extract Embedding Vectors"
      ],
      "metadata": {
        "id": "rhfAd4vfHWPA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "from torch.utils.data import DataLoader,TensorDataset\n",
        "\n",
        "batch_values = list(verse_complete_dict_nrmlz.values())\n",
        "encoding= tokenize(batch_values)\n",
        "\n",
        "dataset=TensorDataset(encoding.input_ids, encoding.attention_mask)\n",
        "dataloader = DataLoader(dataset,batch_size=128,drop_last=False,shuffle=False)\n",
        "\n",
        "predictions = []\n",
        "with torch.no_grad():\n",
        "    for (input_ids, attention_mask) in dataloader:\n",
        "        prediction = model(input_ids.to(device),attention_mask.to(device))\n",
        "        predictions.append(prediction.last_hidden_state)\n",
        "\n",
        "predictions = torch.cat(predictions,dim=0)"
      ],
      "metadata": {
        "id": "S7UcZLFzW2Ty"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Compute Similarity Score"
      ],
      "metadata": {
        "id": "NR6SbLXxHcRJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "attention_mask=encoding.attention_mask.unsqueeze(-1).expand(predictions.shape).float()\n",
        "# for filtering out unnecessary ones\n",
        "mask_embeddings=predictions.cpu() * attention_mask\n",
        "\n",
        "summed = torch.sum(mask_embeddings,dim=1)\n",
        "count = torch.clamp(attention_mask.sum(dim=1),min=1e-9)\n",
        "mean_embedding = summed / count\n",
        "mean_embedding.shape\n",
        "\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "COMPARE_FROM = 20\n",
        "mean_embedding = mean_embedding.numpy()\n",
        "similarity=cosine_similarity(\n",
        "    [mean_embedding[COMPARE_FROM]],\n",
        "    mean_embedding \n",
        ").squeeze()\n",
        "\n",
        "most_similar=similarity.argsort()[-10:][::-1]\n",
        "verse_complete=pd.DataFrame(verse_complete_dict_nrmlz.values())\n",
        "print(verse_complete.iloc[COMPARE_FROM].values)\n",
        "pd.set_option('display.max_colwidth', None)\n",
        "\n",
        "verse_complete.iloc[most_similar]"
      ],
      "metadata": {
        "id": "aR06klpMvA0H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "9bEmLXLe1OzS"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Similarity with fine-tunning"
      ],
      "metadata": {
        "id": "F_LYXmc8Hq4k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install transformers -Uqq"
      ],
      "metadata": {
        "id": "NarvzJ70HvkZ"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import BertTokenizer, BertForMaskedLM\n",
        "import torch\n",
        "from transformers import AdamW\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "\n",
        "# Mini:   asafaya/bert-mini-arabic\n",
        "# Medium: asafaya/bert-medium-arabic\n",
        "# Base:   asafaya/bert-base-arabic\n",
        "# Large:  asafaya/bert-large-arabic\n",
        "\n",
        "tokenizer = BertTokenizer.from_pretrained(\"asafaya/bert-base-arabic\")\n",
        "model = BertForMaskedLM.from_pretrained(\"asafaya/bert-base-arabic\")\n",
        "\n",
        "model=model.to(device)\n",
        "model.train()\n",
        "\n",
        "optim = AdamW(model.parameters(), lr=5e-5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3kc9pE0ClXrr",
        "outputId": "4af9f947-71b2-4fd8-acb2-e873bad11e53"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:309: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  FutureWarning,\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "raw_data = list(verse_complete_dict_nrmlz.values())\n",
        "raw_data= raw_data+list(nahj_complete_dict_nrmlz.values())\n",
        "raw_data= raw_data +list(sahife_complete_dict_nrmlz)\n",
        "inputs=tokenize(raw_data)\n",
        "inputs['labels'] = inputs.input_ids.detach().clone()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 242
        },
        "id": "AycyUs_Im1_6",
        "outputId": "f4a3391d-9ef9-48ac-8657-7d59b2386af6"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-6-df0bd0ff8e04>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mraw_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mverse_complete_dict_nrmlz\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mraw_data\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mraw_data\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnahj_complete_dict_nrmlz\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mraw_data\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mraw_data\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msahife_complete_dict_nrmlz\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mraw_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'labels'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'verse_complete_dict_nrmlz' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "rand = torch.rand(inputs.input_ids.shape)\n",
        "mask_arr = (rand < 0.15) * (inputs.input_ids != 101) * \\\n",
        "           (inputs.input_ids != 102) * (inputs.input_ids != 0)\n",
        "mask_arr"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EJ3CUrropGdd",
        "outputId": "a5bb7bbe-232d-4324-bd05-8b34d5d57e89"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[False, False, False,  ..., False, False, False],\n",
              "        [False, False, False,  ..., False, False, False],\n",
              "        [False,  True, False,  ..., False, False, False],\n",
              "        ...,\n",
              "        [False, False, False,  ..., False, False, False],\n",
              "        [ True,  True,  True,  ..., False, False, False],\n",
              "        [False,  True, False,  ..., False, False, False]])"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "selection = []\n",
        "\n",
        "for i in range(inputs.input_ids.shape[0]):\n",
        "    selection.append(\n",
        "        torch.flatten(mask_arr[i].nonzero()).tolist()\n",
        "    )\n",
        "\n",
        "for i in range(inputs.input_ids.shape[0]):\n",
        "    inputs.input_ids[i, selection[i]] = 103 #masked_tokens"
      ],
      "metadata": {
        "id": "wnf6AyR5qBmW"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm import tqdm  # for our progress bar\n",
        "\n",
        "\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "dataset=TensorDataset(inputs.input_ids, inputs.attention_mask,inputs.labels)\n",
        "dataloader = DataLoader(dataset,batch_size=64,drop_last=False,shuffle=True)\n",
        "\n",
        "\n",
        "epochs = 2\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    loop = tqdm(dataloader, leave=True)\n",
        "    for batch in loop:\n",
        "        optim.zero_grad()\n",
        "\n",
        "        input_ids, attention_mask,labels = batch\n",
        "        outputs = model(input_ids.to(device), attention_mask=attention_mask.to(device),\n",
        "                        labels=labels.to(device))\n",
        "        loss = outputs.loss\n",
        "        loss.backward()\n",
        "        optim.step()\n",
        "        loop.set_description(f'Epoch {epoch}')\n",
        "        loop.set_postfix(loss=loss.item())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u-F1YAaDqKVw",
        "outputId": "610ab9b3-4446-40a9-c046-868c036a8a4a"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 0: 100%|██████████| 125/125 [01:48<00:00,  1.15it/s, loss=0.193]\n",
            "Epoch 1: 100%|██████████| 125/125 [01:47<00:00,  1.16it/s, loss=0.0885]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.save_pretrained(\"model-trained-on-arabic\")\n"
      ],
      "metadata": {
        "id": "BNPRKm9pyyMJ"
      },
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer, AutoModel\n",
        "import torch\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"asafaya/bert-base-arabic\")\n",
        "model = AutoModel.from_pretrained(\"model-trained-on-arabic\")\n",
        "model=model.to(device)\n",
        "model.eval()"
      ],
      "metadata": {
        "id": "P-ex8p-sy-et"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "from torch.utils.data import DataLoader,TensorDataset\n",
        "\n",
        "def get_mean_embedding(model,sentences):\n",
        "    encoding= tokenize(sentences)\n",
        "\n",
        "    dataset=TensorDataset(encoding.input_ids, encoding.attention_mask)\n",
        "    dataloader = DataLoader(dataset,batch_size=128,drop_last=False,shuffle=False)\n",
        "\n",
        "    predictions = []\n",
        "    with torch.no_grad():\n",
        "        for (input_ids, attention_mask) in dataloader:\n",
        "            prediction = model(input_ids.to(device),attention_mask.to(device))\n",
        "            predictions.append(prediction.last_hidden_state)\n",
        "\n",
        "    predictions = torch.cat(predictions,dim=0)\n",
        "\n",
        "    attention_mask=encoding.attention_mask.unsqueeze(-1).expand(predictions.shape).float()\n",
        "    # for filtering out unnecessary ones\n",
        "    mask_embeddings=predictions.cpu() * attention_mask\n",
        "\n",
        "    summed = torch.sum(mask_embeddings,dim=1)\n",
        "    count = torch.clamp(attention_mask.sum(dim=1),min=1e-9)\n",
        "    mean_embedding = summed / count\n",
        "\n",
        "    return mean_embedding"
      ],
      "metadata": {
        "id": "kAWvG0dJrHxM"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mean_embedding = get_mean_embedding(model,list(verse_complete_dict_nrmlz.values()))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        },
        "id": "alvfW5ys0h7h",
        "outputId": "597269f9-7c4f-454d-9fc4-7cff2173a45c"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-3a600abcbbe6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmean_embedding\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_mean_embedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mverse_complete_dict_nrmlz\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "COMPARE_FROM = 10\n",
        "mean_embedding = mean_embedding.numpy()\n",
        "similarity=cosine_similarity(\n",
        "    [mean_embedding[COMPARE_FROM]],\n",
        "    mean_embedding \n",
        ").squeeze()\n",
        "\n",
        "most_similar=similarity.argsort()[-10:][::-1]\n",
        "verse_complete=pd.DataFrame(verse_complete_dict_nrmlz.values())\n",
        "print(verse_complete.iloc[COMPARE_FROM].values)\n",
        "pd.set_option('display.max_colwidth', None)\n",
        "\n",
        "verse_complete.iloc[most_similar]"
      ],
      "metadata": {
        "id": "16688MjIuRjD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "Ek6fNhS4zpQ4"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}